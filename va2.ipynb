{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Install and import Gemini\n",
        "try:\n",
        "    import google.generativeai as genai\n",
        "    GEMINI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Installing Gemini...\")\n",
        "    os.system(\"pip install -q google-generativeai\")\n",
        "    import google.generativeai as genai\n",
        "    GEMINI_AVAILABLE = True\n",
        "\n",
        "#\n",
        "api = 'AIzaSyBQXPfWI6etj89lYogiBgL2mokBudO2zV0'\n",
        "\n",
        "class VirtuTA:\n",
        "    \"\"\"Fast Virtual Teaching Assistant\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.chat_history = []\n",
        "        self.session_start = datetime.now()\n",
        "\n",
        "        # Auto-configure Gemini with your API key\n",
        "        print(\"ğŸ”‘ Configuring Gemini with your API key...\")\n",
        "        try:\n",
        "            genai.configure(api_key=api)\n",
        "            self.model = genai.GenerativeModel('gemini-pro')\n",
        "            self.gemini_enabled = True\n",
        "            print(\"âœ… Gemini AI activated successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Gemini setup issue: {e}\")\n",
        "            self.gemini_enabled = False\n",
        "\n",
        "    def generate_response(self, query, course=\"Computer Science\", difficulty=\"Intermediate\"):\n",
        "        \"\"\"Generate fast response\"\"\"\n",
        "        if not query.strip():\n",
        "            return \"Please ask me something! ğŸ˜Š\"\n",
        "\n",
        "        # Add user message\n",
        "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
        "        self.chat_history.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": query,\n",
        "            \"time\": timestamp\n",
        "        })\n",
        "\n",
        "        # Generate response\n",
        "        if self.gemini_enabled:\n",
        "            response = self._get_gemini_response(query, course, difficulty)\n",
        "        else:\n",
        "            response = self._get_fallback_response(query)\n",
        "\n",
        "        # Add AI response\n",
        "        self.chat_history.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": response,\n",
        "            \"time\": datetime.now().strftime(\"%H:%M:%S\")\n",
        "        })\n",
        "\n",
        "        return self._format_chat_history()\n",
        "\n",
        "    def _get_gemini_response(self, query, course, difficulty):\n",
        "        \"\"\"Fast Gemini response\"\"\"\n",
        "        try:\n",
        "            # Keep context short for speed\n",
        "            context = \"\"\n",
        "            if len(self.chat_history) > 0:\n",
        "                recent = self.chat_history[-4:]  # Last 4 messages only\n",
        "                for msg in recent:\n",
        "                    if msg[\"role\"] == \"user\":\n",
        "                        context += f\"Student: {msg['content']}\\n\"\n",
        "\n",
        "            prompt = f\"\"\"You are VirtuTA, a friendly virtual teaching assistant.\n",
        "\n",
        "Previous context: {context}\n",
        "\n",
        "Current question: {query}\n",
        "Subject: {course}\n",
        "Level: {difficulty}\n",
        "\n",
        "Give a helpful, concise response (2-3 paragraphs max). Be conversational and encouraging.\"\"\"\n",
        "\n",
        "            # Generate with timeout\n",
        "            response = self.model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    max_output_tokens=500,  # Limit for speed\n",
        "                    temperature=0.7,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            return response.text.strip() if response.text else \"Let me help you with that! Could you rephrase your question?\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"I'm having a small technical issue, but I can still help! What would you like to know about {course}?\"\n",
        "\n",
        "    def _get_fallback_response(self, query):\n",
        "        \"\"\"Quick fallback responses\"\"\"\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        if any(word in query_lower for word in [\"hello\", \"hi\", \"hey\"]):\n",
        "            return \"ğŸ‘‹ Hello! I'm VirtuTA, your AI teaching assistant. What would you like to learn today?\"\n",
        "        elif \"help\" in query_lower:\n",
        "            return \"ğŸ“ I'm here to help! Ask me about any subject - math, science, programming, or study tips!\"\n",
        "        else:\n",
        "            return f\"Great question! I can help explain that concept. What specifically would you like to know?\"\n",
        "\n",
        "    def _format_chat_history(self):\n",
        "        \"\"\"Format chat for display - FAST\"\"\"\n",
        "        if not self.chat_history:\n",
        "            return \"ğŸ’¬ Welcome to VirtuTA! Ask me anything! ğŸš€\"\n",
        "\n",
        "        formatted = \"\"\n",
        "        for msg in self.chat_history:\n",
        "            if msg[\"role\"] == \"user\":\n",
        "                formatted += f\"\\n**ğŸ‘¨â€ğŸ“ You [{msg['time']}]:**\\n{msg['content']}\\n\\n\"\n",
        "            else:\n",
        "                formatted += f\"**ğŸ¤– VirtuTA:**\\n{msg['content']}\\n\\n\" + \"â”€\"*50 + \"\\n\"\n",
        "\n",
        "        return formatted\n",
        "\n",
        "    def clear_chat(self):\n",
        "        \"\"\"Clear chat history\"\"\"\n",
        "        self.chat_history = []\n",
        "        return \"ğŸ’¬ Welcome to VirtuTA! Ask me anything! ğŸš€\"\n",
        "\n",
        "    def get_stats(self):\n",
        "        \"\"\"Quick stats\"\"\"\n",
        "        user_count = len([m for m in self.chat_history if m[\"role\"] == \"user\"])\n",
        "        duration = int((datetime.now() - self.session_start).total_seconds() / 60)\n",
        "        return f\"\"\"ğŸ“Š Session Stats:\n",
        "ğŸ’¬ Questions Asked: {user_count}\n",
        "â±ï¸ Time Active: {duration} min\n",
        "ğŸ¤– Status: {\"Gemini AI âœ…\" if self.gemini_enabled else \"Basic Mode\"}\"\"\"\n",
        "\n",
        "# Initialize VirtuTA with your API\n",
        "print(\"ğŸš€ Starting VirtuTA...\")\n",
        "virtuta = VirtuTA()\n",
        "\n",
        "def chat_response(message, course, difficulty, history):\n",
        "    \"\"\"Handle chat - OPTIMIZED FOR SPEED\"\"\"\n",
        "    if not message.strip():\n",
        "        current_history = virtuta._format_chat_history()\n",
        "        return current_history, \"\"\n",
        "\n",
        "    # Generate response (this updates internal history)\n",
        "    updated_history = virtuta.generate_response(message, course, difficulty)\n",
        "\n",
        "    return updated_history, \"\"  # Return updated chat and clear input\n",
        "\n",
        "def clear_conversation():\n",
        "    \"\"\"Clear chat\"\"\"\n",
        "    cleared_history = virtuta.clear_chat()\n",
        "    return cleared_history, \"ğŸ—‘ï¸ Chat cleared!\"\n",
        "\n",
        "def show_stats():\n",
        "    \"\"\"Show stats\"\"\"\n",
        "    return virtuta.get_stats()\n",
        "\n",
        "def show_examples():\n",
        "    \"\"\"Quick examples\"\"\"\n",
        "    examples = [\n",
        "        \"Hello! How can you help me?\",\n",
        "        \"Explain recursion in simple terms\",\n",
        "        \"Help me with calculus derivatives\",\n",
        "        \"What's the best way to study for exams?\",\n",
        "        \"How does machine learning work?\"\n",
        "    ]\n",
        "    return \"\\n\".join([f\"â€¢ {ex}\" for ex in examples])\n",
        "\n",
        "# Create SIMPLE, FAST interface\n",
        "with gr.Blocks(title=\"VirtuTA - Fast AI Teaching Assistant\", theme=gr.themes.Soft()) as demo:\n",
        "\n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"text-align: center; padding: 20px; background: linear-gradient(90deg, #4CAF50, #45a049); color: white; border-radius: 10px; margin-bottom: 20px;\">\n",
        "        <h1>ğŸš€ VirtuTA - AI Teaching Assistant</h1>\n",
        "        <p>âœ… Gemini AI Active â€¢ Fast Responses â€¢ Ready to Help!</p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            # Main chat area\n",
        "            chatbox = gr.Textbox(\n",
        "                label=\"ğŸ’¬ Chat with VirtuTA\",\n",
        "                value=\"ğŸ’¬ Welcome to VirtuTA! Ask me anything! ğŸš€\",\n",
        "                lines=15,\n",
        "                max_lines=20,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "            # Input area\n",
        "            with gr.Row():\n",
        "                user_input = gr.Textbox(\n",
        "                    label=\"ğŸ’­ Your Question\",\n",
        "                    placeholder=\"Ask me anything... (e.g., 'Hello', 'Explain binary search', 'Help with math')\",\n",
        "                    lines=2,\n",
        "                    scale=4\n",
        "                )\n",
        "                send_btn = gr.Button(\"Send ğŸš€\", variant=\"primary\", scale=1)\n",
        "\n",
        "            # Quick actions\n",
        "            with gr.Row():\n",
        "                clear_btn = gr.Button(\"ğŸ—‘ï¸ Clear\", variant=\"secondary\")\n",
        "                stats_btn = gr.Button(\"ğŸ“Š Stats\", variant=\"secondary\")\n",
        "                examples_btn = gr.Button(\"ğŸ’¡ Examples\", variant=\"secondary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### âš™ï¸ Settings\")\n",
        "\n",
        "            # Status\n",
        "            status_box = gr.Textbox(\n",
        "                label=\"ğŸ”‹ Status\",\n",
        "                value=\"âœ… Gemini AI Active\\nğŸš€ Ready for questions!\\nğŸ”‘ Using your API key\",\n",
        "                interactive=False,\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            # Quick settings\n",
        "            course_dropdown = gr.Dropdown(\n",
        "                label=\"ğŸ“š Subject\",\n",
        "                choices=[\"Computer Science\", \"Mathematics\", \"Physics\", \"Chemistry\", \"Biology\", \"General\"],\n",
        "                value=\"Computer Science\"\n",
        "            )\n",
        "\n",
        "            level_dropdown = gr.Dropdown(\n",
        "                label=\"ğŸ¯ Level\",\n",
        "                choices=[\"Beginner\", \"Intermediate\", \"Advanced\"],\n",
        "                value=\"Intermediate\"\n",
        "            )\n",
        "\n",
        "            # Stats display\n",
        "            stats_display = gr.Textbox(\n",
        "                label=\"ğŸ“ˆ Session Info\",\n",
        "                value=virtuta.get_stats(),\n",
        "                interactive=False,\n",
        "                lines=4\n",
        "            )\n",
        "\n",
        "    # Connect events for SPEED\n",
        "    def quick_response(msg, course, level, hist):\n",
        "        new_hist, cleared = chat_response(msg, course, level, hist)\n",
        "        new_stats = show_stats()\n",
        "        return new_hist, cleared, new_stats\n",
        "\n",
        "    # Wire up events\n",
        "    send_btn.click(\n",
        "        fn=quick_response,\n",
        "        inputs=[user_input, course_dropdown, level_dropdown, chatbox],\n",
        "        outputs=[chatbox, user_input, stats_display]\n",
        "    )\n",
        "\n",
        "    user_input.submit(\n",
        "        fn=quick_response,\n",
        "        inputs=[user_input, course_dropdown, level_dropdown, chatbox],\n",
        "        outputs=[chatbox, user_input, stats_display]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_conversation,\n",
        "        outputs=[chatbox, status_box]\n",
        "    )\n",
        "\n",
        "    stats_btn.click(\n",
        "        fn=show_stats,\n",
        "        outputs=[stats_display]\n",
        "    )\n",
        "\n",
        "    examples_btn.click(\n",
        "        fn=show_examples,\n",
        "        outputs=[user_input]\n",
        "    )\n",
        "\n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"margin-top: 15px; padding: 15px; background: #e8f5e8; border-radius: 8px; text-align: center;\">\n",
        "        <h4 style=\"color: #2e7d2e; margin: 0;\">ğŸ¯ Ready to Go!</h4>\n",
        "        <p style=\"margin: 10px 0 0 0; color: #2e7d2e;\">Your app  is active. Just start asking questions!</p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "# Launch with your API key active\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"ğŸ”‘ Using API key: {api[:20]}...\")\n",
        "    print(\"ğŸš€ Launching optimized VirtuTA...\")\n",
        "\n",
        "    demo.launch(\n",
        "        share=True,\n",
        "        debug=False,\n",
        "        show_error=True,\n",
        "        quiet=False\n",
        "    )\n",
        "\n",
        "    print(\"âœ… VirtuTA is ready!!!\")\n",
        "    print(\"ğŸ’¬ Try asking: 'Hello' or any question!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "uT7NpZSCocC2",
        "outputId": "a064b33c-3829-4957-b44e-d7090d0d98aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Starting VirtuTA...\n",
            "ğŸ”‘ Configuring Gemini with your API key...\n",
            "âœ… Gemini AI activated successfully!\n",
            "ğŸ”‘ Using API key: AIzaSyBQXPfWI6etj89l...\n",
            "ğŸš€ Launching optimized VirtuTA...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://88b7ed6d1ca6fc7add.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://88b7ed6d1ca6fc7add.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… VirtuTA is ready! Your Gemini API is active!\n",
            "ğŸ’¬ Try asking: 'Hello' or any question!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oMgtxSIcp8a2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}