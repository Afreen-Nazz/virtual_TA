{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# WORKING CHATBOT + API DEBUGGER\n",
        "import gradio as gr\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "\n",
        "# Your API key\n",
        "API_KEY = 'AIzaSyBQXPfWI6etj89lYogiBgL2mokBudO2zV0'\n",
        "\n",
        "# Global status\n",
        "api_status = \"‚ùå Not tested yet\"\n",
        "model = None\n",
        "last_error = \"\"\n",
        "\n",
        "def test_api_detailed():\n",
        "    \"\"\"Detailed API test with full error reporting\"\"\"\n",
        "    global api_status, model, last_error\n",
        "\n",
        "    try:\n",
        "        print(\"üîç Testing API step by step...\")\n",
        "\n",
        "        # Step 1: Install\n",
        "        import subprocess\n",
        "        result = subprocess.run(['pip', 'install', '-q', 'google-generativeai'],\n",
        "                              capture_output=True, text=True, timeout=30)\n",
        "        print(f\"üì¶ Install result: {result.returncode}\")\n",
        "\n",
        "        # Step 2: Import\n",
        "        import google.generativeai as genai\n",
        "        print(\"‚úÖ Import successful\")\n",
        "\n",
        "        # Step 3: Configure\n",
        "        genai.configure(api_key=API_KEY)\n",
        "        print(\"‚úÖ API key configured\")\n",
        "\n",
        "        # Step 4: Try different models (gemini-pro might be deprecated)\n",
        "        model_names = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']\n",
        "\n",
        "        for model_name in model_names:\n",
        "            try:\n",
        "                print(f\"üß™ Trying model: {model_name}\")\n",
        "                model = genai.GenerativeModel(model_name)\n",
        "                print(f\"‚úÖ Model created: {model_name}\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå {model_name} failed: {e}\")\n",
        "                continue\n",
        "        else:\n",
        "            raise Exception(\"All models failed to load\")\n",
        "\n",
        "        # Step 5: Test generation with timeout\n",
        "        print(\"üß™ Testing actual generation...\")\n",
        "        response = model.generate_content(\n",
        "            \"Say exactly: Hello I am working\",\n",
        "            generation_config=genai.types.GenerationConfig(\n",
        "                max_output_tokens=20,\n",
        "                temperature=0\n",
        "            ),\n",
        "            request_options={\"timeout\": 10}  # 10 second timeout\n",
        "        )\n",
        "\n",
        "        print(f\"üìù Response object: {type(response)}\")\n",
        "        print(f\"üìù Response text: {response.text}\")\n",
        "        print(f\"üéØ Using model: {model.model_name if hasattr(model, 'model_name') else 'unknown'}\")\n",
        "\n",
        "        if response and response.text:\n",
        "            api_status = \"‚úÖ API WORKING!\"\n",
        "            return True, f\"‚úÖ SUCCESS! Gemini said: '{response.text}'\"\n",
        "        else:\n",
        "            api_status = \"‚ùå Empty response\"\n",
        "            return False, \"‚ùå API responded but returned empty text\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_details = traceback.format_exc()\n",
        "        last_error = str(e)\n",
        "        api_status = f\"‚ùå Error: {str(e)[:50]}...\"\n",
        "\n",
        "        print(f\"‚ùå Full error: {error_details}\")\n",
        "\n",
        "        # Common error messages\n",
        "        if \"API_KEY\" in str(e):\n",
        "            return False, \"‚ùå API KEY ERROR: Your key might be invalid or expired\"\n",
        "        elif \"quota\" in str(e).lower():\n",
        "            return False, \"‚ùå QUOTA ERROR: You might have exceeded API limits\"\n",
        "        elif \"timeout\" in str(e).lower():\n",
        "            return False, \"‚ùå TIMEOUT ERROR: API is responding too slowly\"\n",
        "        elif \"permission\" in str(e).lower():\n",
        "            return False, \"‚ùå PERMISSION ERROR: API key doesn't have access\"\n",
        "        else:\n",
        "            return False, f\"‚ùå UNKNOWN ERROR: {str(e)}\"\n",
        "\n",
        "def smart_response(message):\n",
        "    \"\"\"Always working smart responses\"\"\"\n",
        "    msg = message.lower().strip()\n",
        "\n",
        "    responses = {\n",
        "        \"hello\": \"üëã **Hello there!** I'm VirtuTA, your AI teaching assistant!\\n\\nüéì I can help you with:\\n‚Ä¢ **Programming** (Python, Java, algorithms)\\n‚Ä¢ **Mathematics** (calculus, algebra, statistics)\\n‚Ä¢ **Sciences** (physics, chemistry, biology)\\n‚Ä¢ **Study tips** and learning strategies\\n\\nWhat would you like to learn today?\",\n",
        "\n",
        "        \"help\": \"üÜò **I'm here to help!** Here's what I can do:\\n\\nüìö **Explain Concepts**\\n‚Ä¢ Break down complex topics\\n‚Ä¢ Provide step-by-step explanations\\n‚Ä¢ Give real-world examples\\n\\nüßÆ **Solve Problems**\\n‚Ä¢ Math equations and proofs\\n‚Ä¢ Programming challenges\\n‚Ä¢ Science problems\\n\\nüí° **Study Support**\\n‚Ä¢ Learning strategies\\n‚Ä¢ Exam preparation tips\\n‚Ä¢ Time management advice\\n\\nJust ask me anything!\",\n",
        "\n",
        "        \"programming\": \"üíª **Programming Help Available!**\\n\\nüêç **Languages I can help with:**\\n‚Ä¢ Python, Java, C++, JavaScript\\n‚Ä¢ HTML/CSS, SQL, R\\n\\nüß† **Topics I cover:**\\n‚Ä¢ Data structures & algorithms\\n‚Ä¢ Object-oriented programming\\n‚Ä¢ Debugging techniques\\n‚Ä¢ Best practices\\n\\nüìù **What I can do:**\\n‚Ä¢ Explain code concepts\\n‚Ä¢ Help debug errors\\n‚Ä¢ Suggest improvements\\n‚Ä¢ Provide examples\\n\\nWhat programming topic interests you?\",\n",
        "\n",
        "        \"math\": \"üî¢ **Mathematics Assistance Ready!**\\n\\nüìä **Areas I specialize in:**\\n‚Ä¢ Calculus (derivatives, integrals)\\n‚Ä¢ Algebra (equations, functions)\\n‚Ä¢ Statistics & probability\\n‚Ä¢ Linear algebra\\n‚Ä¢ Discrete mathematics\\n\\n‚ö° **How I help:**\\n‚Ä¢ Step-by-step solutions\\n‚Ä¢ Concept explanations\\n‚Ä¢ Practice problems\\n‚Ä¢ Exam preparation\\n\\nWhat math topic can I help clarify?\",\n",
        "\n",
        "        \"science\": \"üî¨ **Science Help Available!**\\n\\nüß™ **Subjects I cover:**\\n‚Ä¢ Physics (mechanics, electromagnetism)\\n‚Ä¢ Chemistry (organic, inorganic, physical)\\n‚Ä¢ Biology (cell biology, genetics, ecology)\\n‚Ä¢ Earth sciences\\n\\nüéØ **My approach:**\\n‚Ä¢ Clear explanations\\n‚Ä¢ Visual analogies\\n‚Ä¢ Practice problems\\n‚Ä¢ Real-world applications\\n\\nWhich science topic interests you?\",\n",
        "\n",
        "        \"study\": \"üìñ **Study Strategies & Tips!**\\n\\nüéØ **Effective Study Methods:**\\n‚Ä¢ Spaced repetition for memorization\\n‚Ä¢ Active recall techniques\\n‚Ä¢ Pomodoro technique for focus\\n‚Ä¢ Mind mapping for connections\\n\\n‚è∞ **Time Management:**\\n‚Ä¢ Creating study schedules\\n‚Ä¢ Prioritizing tasks\\n‚Ä¢ Breaking down large topics\\n‚Ä¢ Managing procrastination\\n\\n‚úÖ **Exam Preparation:**\\n‚Ä¢ Practice test strategies\\n‚Ä¢ Review techniques\\n‚Ä¢ Stress management\\n\\nWhat specific study challenge can I help with?\"\n",
        "    }\n",
        "\n",
        "    # Check for specific topics\n",
        "    if any(word in msg for word in [\"hello\", \"hi\", \"hey\", \"start\"]):\n",
        "        return responses[\"hello\"]\n",
        "    elif \"help\" in msg or \"assist\" in msg:\n",
        "        return responses[\"help\"]\n",
        "    elif any(word in msg for word in [\"program\", \"code\", \"algorithm\", \"python\", \"java\"]):\n",
        "        return responses[\"programming\"]\n",
        "    elif any(word in msg for word in [\"math\", \"calculus\", \"algebra\", \"equation\"]):\n",
        "        return responses[\"math\"]\n",
        "    elif any(word in msg for word in [\"science\", \"physics\", \"chemistry\", \"biology\"]):\n",
        "        return responses[\"science\"]\n",
        "    elif any(word in msg for word in [\"study\", \"exam\", \"learn\", \"prepare\"]):\n",
        "        return responses[\"study\"]\n",
        "    else:\n",
        "        return f\"ü§î **Great question about:** *{message}*\\n\\nüìö I'd love to help explain that topic! To give you the best answer, could you tell me:\\n\\n‚Ä¢ What specific aspect interests you most?\\n‚Ä¢ What's your current understanding level?\\n‚Ä¢ Is this for a particular course or project?\\n\\nThe more details you provide, the better I can tailor my explanation!\"\n",
        "\n",
        "def chat_function(message, history):\n",
        "    \"\"\"Main chat function that always works\"\"\"\n",
        "    global api_status, model\n",
        "\n",
        "    if not message.strip():\n",
        "        return history, history\n",
        "\n",
        "    # Always try smart response first (instant)\n",
        "    smart_reply = smart_response(message)\n",
        "\n",
        "    # Try Gemini if available\n",
        "    gemini_reply = None\n",
        "    if model:\n",
        "        try:\n",
        "            response = model.generate_content(\n",
        "                f\"You are VirtuTA, a helpful teaching assistant. Answer this student question clearly and helpfully: {message}\",\n",
        "                generation_config={'max_output_tokens': 300, 'temperature': 0.7}\n",
        "            )\n",
        "            if response and response.text:\n",
        "                gemini_reply = response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Gemini failed: {e}\")\n",
        "\n",
        "    # Use best available response\n",
        "    if gemini_reply:\n",
        "        bot_response = f\"ü§ñ **VirtuTA (AI Enhanced):**\\n\\n{gemini_reply}\"\n",
        "    else:\n",
        "        bot_response = f\"ü§ñ **VirtuTA (Smart Mode):**\\n\\n{smart_reply}\"\n",
        "\n",
        "    # Add to history\n",
        "    history.append([message, bot_response])\n",
        "    return history, history\n",
        "\n",
        "def run_api_test():\n",
        "    \"\"\"Run API test and return results\"\"\"\n",
        "    success, message = test_api_detailed()\n",
        "    return message, api_status\n",
        "\n",
        "def get_debug_info():\n",
        "    \"\"\"Get debug information\"\"\"\n",
        "    return f\"\"\"üîç **Debug Information:**\n",
        "\n",
        "üîë **API Key:** {API_KEY[:20]}...{API_KEY[-5:]}\n",
        "üì° **Current Status:** {api_status}\n",
        "‚ùå **Last Error:** {last_error or 'None'}\n",
        "ü§ñ **Model Status:** {'Loaded' if model else 'Not loaded'}\n",
        "‚è∞ **Time:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "üí° **Troubleshooting Tips:**\n",
        "‚Ä¢ Try clicking \"Test API\" button\n",
        "‚Ä¢ Check if your API key is valid at: https://makersuite.google.com/app/apikey\n",
        "‚Ä¢ Make sure you have API quota remaining\n",
        "‚Ä¢ Check your internet connection\n",
        "\"\"\"\n",
        "\n",
        "# Create working interface\n",
        "with gr.Blocks(title=\"VirtuTA - Always Working!\", css=\".chatbot {height: 500px !important}\") as demo:\n",
        "\n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"text-align: center; padding: 20px; background: linear-gradient(45deg, #FF6B35, #F7931E); color: white; border-radius: 15px; margin-bottom: 20px;\">\n",
        "        <h1>üéì VirtuTA - AI Teaching Assistant</h1>\n",
        "        <h3>‚úÖ ALWAYS WORKING - Smart Responses Guaranteed!</h3>\n",
        "        <p>Ask me anything - I'll help with or without the API!</p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            chatbot = gr.Chatbot(\n",
        "                label=\"üí¨ Chat with VirtuTA\",\n",
        "                height=500,\n",
        "                show_label=True\n",
        "            )\n",
        "\n",
        "            msg = gr.Textbox(\n",
        "                label=\"üí≠ Your Question\",\n",
        "                placeholder=\"Ask me anything! Try: 'Hello', 'Explain recursion', 'Help with calculus'\",\n",
        "                lines=3,\n",
        "                max_lines=5\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                send_btn = gr.Button(\"Send üöÄ\", variant=\"primary\", scale=2)\n",
        "                clear_btn = gr.Button(\"Clear üóëÔ∏è\", scale=1)\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### üîß API Diagnostics\")\n",
        "\n",
        "            test_btn = gr.Button(\"üß™ Test Gemini API\", variant=\"secondary\")\n",
        "\n",
        "            api_result = gr.Textbox(\n",
        "                label=\"üîç API Test Result\",\n",
        "                value=\"Click 'Test Gemini API' to check your key\",\n",
        "                lines=4,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "            status_box = gr.Textbox(\n",
        "                label=\"üìä Current Status\",\n",
        "                value=api_status,\n",
        "                lines=2,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "            debug_btn = gr.Button(\"üêõ Debug Info\")\n",
        "\n",
        "            debug_info = gr.Textbox(\n",
        "                label=\"üîç Debug Details\",\n",
        "                lines=8,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "    # Example questions\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"Hello VirtuTA! How can you help me?\"],\n",
        "            [\"Explain how binary search works\"],\n",
        "            [\"Help me understand calculus derivatives\"],\n",
        "            [\"What's the best way to study for programming exams?\"],\n",
        "            [\"Can you help me debug this Python code?\"]\n",
        "        ],\n",
        "        inputs=[msg],\n",
        "        label=\"üí° Try These Examples (Click to Use)\"\n",
        "    )\n",
        "\n",
        "    # Event handlers\n",
        "    msg.submit(chat_function, [msg, chatbot], [chatbot, chatbot]).then(\n",
        "        lambda: \"\", outputs=[msg]\n",
        "    )\n",
        "\n",
        "    send_btn.click(chat_function, [msg, chatbot], [chatbot, chatbot]).then(\n",
        "        lambda: \"\", outputs=[msg]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(lambda: ([], []), outputs=[chatbot, chatbot])\n",
        "\n",
        "    test_btn.click(run_api_test, outputs=[api_result, status_box])\n",
        "\n",
        "    debug_btn.click(get_debug_info, outputs=[debug_info])\n",
        "\n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"margin-top: 20px; padding: 15px; background: #e8f5e8; border-radius: 10px;\">\n",
        "        <h4 style=\"color: #2d5a3d;\">‚úÖ This Chatbot ALWAYS Works!</h4>\n",
        "        <p style=\"color: #2d5a3d; margin: 0;\">Even if Gemini API fails, you'll get intelligent responses. Click \"Test Gemini API\" to diagnose any issues!</p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "# Test API on startup\n",
        "print(\"üß™ Testing your Gemini API...\")\n",
        "api_test_result = test_api_detailed()\n",
        "print(f\"üîç API Test Result: {api_test_result}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üöÄ Launching ALWAYS-WORKING VirtuTA...\")\n",
        "    print(\"üíØ This version will respond to every message!\")\n",
        "\n",
        "    demo.launch(\n",
        "        share=True,\n",
        "        debug=True,\n",
        "        show_error=True\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ VirtuTA is live and ready!\")\n",
        "    print(\"üí¨ Try asking 'Hello' - you'll get a response no matter what!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wf1tXYSR2g7R",
        "outputId": "026ce5a0-182b-48e7-bd9b-4a438b7305be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-889355488.py:193: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Testing your Gemini API...\n",
            "üîç Testing API step by step...\n",
            "üì¶ Install result: 0\n",
            "‚úÖ Import successful\n",
            "‚úÖ API key configured\n",
            "üß™ Trying model: gemini-1.5-flash\n",
            "‚úÖ Model created: gemini-1.5-flash\n",
            "üß™ Testing actual generation...\n",
            "üìù Response object: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>\n",
            "üìù Response text: Hello, I am working.\n",
            "\n",
            "üéØ Using model: models/gemini-1.5-flash\n",
            "üîç API Test Result: (True, \"‚úÖ SUCCESS! Gemini said: 'Hello, I am working.\\n'\")\n",
            "üöÄ Launching ALWAYS-WORKING VirtuTA...\n",
            "üíØ This version will respond to every message!\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8da6bcb7f2b89b7b3f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8da6bcb7f2b89b7b3f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Testing API step by step...\n",
            "üì¶ Install result: 0\n",
            "‚úÖ Import successful\n",
            "‚úÖ API key configured\n",
            "üß™ Trying model: gemini-1.5-flash\n",
            "‚úÖ Model created: gemini-1.5-flash\n",
            "üß™ Testing actual generation...\n",
            "üìù Response object: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>\n",
            "üìù Response text: Hello, I am working.\n",
            "\n",
            "üéØ Using model: models/gemini-1.5-flash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AEx4tYoI3uea"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}